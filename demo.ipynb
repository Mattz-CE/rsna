{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from payload.model import get_model  # Assuming this is available\n",
    "from torch.nn import Sigmoid\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "df = pd.read_csv('./payload/train.csv')\n",
    "base_path = '/kaggle/input/rsna-512/train_images_processed_512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_25204\\3078061251.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(config['path'], map_location=device))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RESNET101:\n\tsize mismatch for resnet.conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 1, 7, 7]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 129\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted! Check the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory for results.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[62], line 96\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Initialize evaluator\u001b[39;00m\n\u001b[0;32m     95\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mModelEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Add image paths\u001b[39;00m\n\u001b[0;32m    100\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39mpatient_id), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39mimage_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    102\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    103\u001b[0m )\n",
      "Cell \u001b[1;32mIn[62], line 19\u001b[0m, in \u001b[0;36mModelEvaluator.__init__\u001b[1;34m(self, model_configs, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, config \u001b[38;5;129;01min\u001b[39;00m model_configs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m get_model(\n\u001b[0;32m     15\u001b[0m         config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marchitecture\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     16\u001b[0m         img_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m     17\u001b[0m         patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marchitecture\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     )\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     21\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\m\\File\\SKL\\A-2024-ZFall\\BI CSE 7743 - Machine Learning and Data Science for Bioinformatics\\A6\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RESNET101:\n\tsize mismatch for resnet.conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 1, 7, 7])."
     ]
    }
   ],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model_configs, device='cuda'):\n",
    "        self.device = device\n",
    "        self.models = {}\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "        self.sigmoid = Sigmoid()\n",
    "        \n",
    "        # Initialize all models\n",
    "        for name, config in model_configs.items():\n",
    "            model = get_model(\n",
    "                config['architecture'],\n",
    "                img_size=512,\n",
    "                patch_size=16 if 'vit' in config['architecture'] else None\n",
    "            )\n",
    "            model.load_state_dict(torch.load(config['path'], map_location=device))\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            self.models[name] = model\n",
    "\n",
    "    def predict_image(self, image_path):\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        predictions = {}\n",
    "        with torch.no_grad():\n",
    "            for name, model in self.models.items():\n",
    "                output = model(tensor)\n",
    "                prob = self.sigmoid(output).item()\n",
    "                predictions[name] = prob\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def visualize_prediction(self, image_path, predictions, true_label, save_path=None):\n",
    "        # Open and resize image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        # Try to load a font, fall back to default if not available\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 20)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Draw true label at the top\n",
    "        label_text = f\"True: {'Positive' if true_label == 1 else 'Negative'}\"\n",
    "        draw.text((10, 10), label_text, fill='white', font=font)\n",
    "        \n",
    "        # Draw predictions\n",
    "        y_position = 40\n",
    "        for model_name, prob in predictions.items():\n",
    "            prediction = \"Positive\" if prob >= 0.5 else \"Negative\"\n",
    "            confidence = prob if prob >= 0.5 else 1 - prob\n",
    "            text = f\"{model_name}: {prediction} ({confidence:.2f})\"\n",
    "            \n",
    "            # Color based on correctness\n",
    "            color = 'green' if (prob >= 0.5) == true_label else 'red'\n",
    "            draw.text((10, y_position), text, fill=color, font=font)\n",
    "            y_position += 25\n",
    "\n",
    "        if save_path:\n",
    "            image.save(save_path)\n",
    "        return image\n",
    "\n",
    "def main():\n",
    "    # Model configurations\n",
    "    model_configs = {\n",
    "        'EfficientNet': {\n",
    "            'architecture': 'effinet',\n",
    "            'path': 'models/run_efficientnet_20241205_114438_ep7_best_auc_model.pth'\n",
    "        },\n",
    "        'ResNet50': {\n",
    "            'architecture': 'resnet',\n",
    "            'path': 'models/run_resnet50_20241208_231720_ep6_best_auc_model.pth'\n",
    "        },\n",
    "        'ResNet101': {\n",
    "            'architecture': 'resnet101',\n",
    "            'path': 'models/run_resnet101_20241204_201138_ep14.pth'\n",
    "        },\n",
    "        'ViT-Base': {\n",
    "            'architecture': 'vit_base',\n",
    "            'path': 'models/run_vit_base_20241207_113554_ep28_best_auc_model.pth'\n",
    "        },\n",
    "        'ViT-Medium': {\n",
    "            'architecture': 'vit_medium',\n",
    "            'path': 'models/run_vit_mediumd_20241209_002034_ep26_best_auc_model.pth'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Initialize evaluator\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    evaluator = ModelEvaluator(model_configs, device)\n",
    "\n",
    "\n",
    "    # Add image paths\n",
    "    df['img_path'] = df.apply(\n",
    "        lambda row: os.path.join(base_path, str(row.patient_id), f\"{str(row.image_id)}.png\"),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Sample 10 images from each class\n",
    "    pos_samples = df[df['cancer'] == 1].sample(10)\n",
    "    neg_samples = df[df['cancer'] == 0].sample(10)\n",
    "    samples = pd.concat([pos_samples, neg_samples])\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs('predictions', exist_ok=True)\n",
    "\n",
    "    # Process each image\n",
    "    for idx, row in samples.iterrows():\n",
    "        predictions = evaluator.predict_image(row['img_path'])\n",
    "        save_path = f\"predictions/pred_{row['patient_id']}_{row['image_id']}.png\"\n",
    "        \n",
    "        evaluator.visualize_prediction(\n",
    "            row['img_path'],\n",
    "            predictions,\n",
    "            row['cancer'],\n",
    "            save_path\n",
    "        )\n",
    "        print(f\"Processed image {row['patient_id']}_{row['image_id']}\")\n",
    "\n",
    "    print(\"Completed! Check the 'predictions' directory for results.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
